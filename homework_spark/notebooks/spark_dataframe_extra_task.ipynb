{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F, types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/21 16:46:45 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"spark://spark-master:7077\").config(\"spark.jars.packages\", \n",
    "                                                                        \"org.apache.hadoop:hadoop-aws-2.7.3\").appName(\"spark-hw\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.1\n"
     ]
    }
   ],
   "source": [
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "actor_df = spark.read.csv('../data/actor.csv', header=True, inferSchema=True)\n",
    "address_df = spark.read.csv('../data/address.csv', header=True, inferSchema=True)\n",
    "category_df = spark.read.csv('../data/category.csv', header=True, inferSchema=True)\n",
    "city_df = spark.read.csv('../data/city.csv', header=True, inferSchema=True)\n",
    "country_df = spark.read.csv('../data/country.csv', header=True, inferSchema=True)\n",
    "customer_df = spark.read.csv('../data/customer.csv', header=True, inferSchema=True)\n",
    "film_df = spark.read.csv('../data/film.csv', header=True, inferSchema=True)\n",
    "film_actor_df = spark.read.csv('../data/film_actor.csv', header=True, inferSchema=True)\n",
    "film_category_df = spark.read.csv('../data/film_category.csv', header=True, inferSchema=True)\n",
    "inventory_df = spark.read.csv('../data/inventory.csv', header=True, inferSchema=True)\n",
    "language_df = spark.read.csv('../data/language.csv', header=True, inferSchema=True)\n",
    "payment_df = spark.read.csv('../data/payment.csv', header=True, inferSchema=True)\n",
    "rental_df = spark.read.csv('../data/rental.csv', header=True, inferSchema=True)\n",
    "staff_df = spark.read.csv('../data/staff.csv', header=True, inferSchema=True)\n",
    "store_df = spark.read.csv('../data/store.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Домашнє завдання на тему Spark SQL\n",
    "\n",
    "Задачі з домашнього завдання на SQL потрібно розвʼязати за допомогою Spark SQL DataFrame API.\n",
    "\n",
    "- Дампи таблиць знаходяться в папці `data`. Датафрейми таблиць вже створені в клітинці вище.\n",
    "- Можете створювати стільки нових клітинок, скільки вам необхідно.\n",
    "- Розвʼязок кожної задачі має бути відображений в самому файлі (використати метод `.show()`)\n",
    "- код має бути оформлений у відповідності із одним із стилем, показаним лектором на занятті 13.\n",
    "\n",
    "**Увага!**\n",
    "Використовувати мову запитів SQL безпосередньо забороняється, потрібно використовувати виключно DataFrame API!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "1.\n",
    "Вивести кількість фільмів в кожній категорії.\n",
    "Результат відсортувати за спаданням."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-------------------+\n",
      "|category_id|       name|        last_update|\n",
      "+-----------+-----------+-------------------+\n",
      "|          1|     Action|2022-02-15 09:46:27|\n",
      "|          2|  Animation|2022-02-15 09:46:27|\n",
      "|          3|   Children|2022-02-15 09:46:27|\n",
      "|          4|   Classics|2022-02-15 09:46:27|\n",
      "|          5|     Comedy|2022-02-15 09:46:27|\n",
      "|          6|Documentary|2022-02-15 09:46:27|\n",
      "|          7|      Drama|2022-02-15 09:46:27|\n",
      "|          8|     Family|2022-02-15 09:46:27|\n",
      "|          9|    Foreign|2022-02-15 09:46:27|\n",
      "|         10|      Games|2022-02-15 09:46:27|\n",
      "+-----------+-----------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------------------+\n",
      "|film_id|category_id|        last_update|\n",
      "+-------+-----------+-------------------+\n",
      "|      1|          6|2022-02-15 10:07:09|\n",
      "|      2|         11|2022-02-15 10:07:09|\n",
      "|      3|          6|2022-02-15 10:07:09|\n",
      "|      4|         11|2022-02-15 10:07:09|\n",
      "|      5|          8|2022-02-15 10:07:09|\n",
      "|      6|          9|2022-02-15 10:07:09|\n",
      "|      7|          5|2022-02-15 10:07:09|\n",
      "|      8|         11|2022-02-15 10:07:09|\n",
      "|      9|         11|2022-02-15 10:07:09|\n",
      "|     10|         15|2022-02-15 10:07:09|\n",
      "+-------+-----------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "film_category_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_film_in_cat_df: DataFrame = film_category_df.join(category_df , on=\"category_id\" , how=\"inner\").groupBy(category_df.name) \\\n",
    "    .agg(f.count(film_category_df.film_id).alias(\"films_cnt\")).orderBy(f.col(\"films_cnt\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|       name|films_cnt|\n",
      "+-----------+---------+\n",
      "|     Sports|       74|\n",
      "|    Foreign|       73|\n",
      "|     Family|       69|\n",
      "|Documentary|       68|\n",
      "|  Animation|       66|\n",
      "|     Action|       64|\n",
      "|        New|       63|\n",
      "|      Drama|       62|\n",
      "|      Games|       61|\n",
      "|     Sci-Fi|       61|\n",
      "|   Children|       60|\n",
      "|     Comedy|       58|\n",
      "|     Travel|       57|\n",
      "|   Classics|       57|\n",
      "|     Horror|       56|\n",
      "|      Music|       51|\n",
      "+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnt_film_in_cat_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "2.\n",
    "Вивести 10 акторів, чиї фільми брали на прокат найбільше.\n",
    "Результат відсортувати за спаданням."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------------+-------------------+\n",
      "|actor_id|first_name|   last_name|        last_update|\n",
      "+--------+----------+------------+-------------------+\n",
      "|       1|  PENELOPE|     GUINESS|2022-02-15 09:34:33|\n",
      "|       2|      NICK|    WAHLBERG|2022-02-15 09:34:33|\n",
      "|       3|        ED|       CHASE|2022-02-15 09:34:33|\n",
      "|       4|  JENNIFER|       DAVIS|2022-02-15 09:34:33|\n",
      "|       5|    JOHNNY|LOLLOBRIGIDA|2022-02-15 09:34:33|\n",
      "|       6|     BETTE|   NICHOLSON|2022-02-15 09:34:33|\n",
      "|       7|     GRACE|      MOSTEL|2022-02-15 09:34:33|\n",
      "|       8|   MATTHEW|   JOHANSSON|2022-02-15 09:34:33|\n",
      "|       9|       JOE|       SWANK|2022-02-15 09:34:33|\n",
      "|      10| CHRISTIAN|       GABLE|2022-02-15 09:34:33|\n",
      "+--------+----------+------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actor_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+--------+-------------------+\n",
      "|inventory_id|film_id|store_id|        last_update|\n",
      "+------------+-------+--------+-------------------+\n",
      "|           1|      1|       1|2022-02-15 10:09:17|\n",
      "|           2|      1|       1|2022-02-15 10:09:17|\n",
      "|           3|      1|       1|2022-02-15 10:09:17|\n",
      "|           4|      1|       1|2022-02-15 10:09:17|\n",
      "|           5|      1|       2|2022-02-15 10:09:17|\n",
      "|           6|      1|       2|2022-02-15 10:09:17|\n",
      "|           7|      1|       2|2022-02-15 10:09:17|\n",
      "|           8|      1|       2|2022-02-15 10:09:17|\n",
      "|           9|      2|       2|2022-02-15 10:09:17|\n",
      "|          10|      2|       2|2022-02-15 10:09:17|\n",
      "+------------+-------+--------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inventory_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-------------------+\n",
      "|actor_id|film_id|        last_update|\n",
      "+--------+-------+-------------------+\n",
      "|       1|      1|2022-02-15 10:05:03|\n",
      "|       1|     23|2022-02-15 10:05:03|\n",
      "|       1|     25|2022-02-15 10:05:03|\n",
      "|       1|    106|2022-02-15 10:05:03|\n",
      "|       1|    140|2022-02-15 10:05:03|\n",
      "|       1|    166|2022-02-15 10:05:03|\n",
      "|       1|    277|2022-02-15 10:05:03|\n",
      "|       1|    361|2022-02-15 10:05:03|\n",
      "|       1|    438|2022-02-15 10:05:03|\n",
      "|       1|    499|2022-02-15 10:05:03|\n",
      "+--------+-------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "film_actor_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_top10_actor_df: DataFrame = actor_df.join(film_actor_df, on=\"actor_id\" , how=\"inner\"). \\\n",
    "                                        join(inventory_df  , on=\"film_id\" ,  how=\"inner\"). \\\n",
    "    groupBy(actor_df.first_name, actor_df.last_name).agg(f.count(inventory_df.inventory_id).alias(\"rent_cnt\")).orderBy(f.col(\"rent_cnt\").desc()).limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------+\n",
      "|first_name|  last_name|rent_cnt|\n",
      "+----------+-----------+--------+\n",
      "|     SUSAN|      DAVIS|     236|\n",
      "|      GINA|  DEGENERES|     214|\n",
      "|   MATTHEW|     CARREY|     198|\n",
      "|      MARY|     KEITEL|     192|\n",
      "|    WALTER|       TORN|     186|\n",
      "|    ANGELA|WITHERSPOON|     184|\n",
      "|     JAYNE|      NOLTE|     177|\n",
      "|       VAL|     BOLGER|     177|\n",
      "|    SANDRA|     KILMER|     174|\n",
      "|     HENRY|      BERRY|     170|\n",
      "+----------+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnt_top10_actor_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "3.\n",
    "Вивести категорія фільмів, на яку було витрачено найбільше грошей\n",
    "в прокаті"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------+---------+------+--------------------+\n",
      "|payment_id|customer_id|staff_id|rental_id|amount|        payment_date|\n",
      "+----------+-----------+--------+---------+------+--------------------+\n",
      "|     16051|        269|       1|       98|  0.99|2022-01-29 01:58:...|\n",
      "|     16065|        274|       1|      147|  2.99|2022-01-25 12:14:...|\n",
      "|     16109|        297|       2|      143|  0.99|2022-01-28 00:49:...|\n",
      "|     16195|        344|       2|      157|  2.99|2022-01-31 05:58:...|\n",
      "|     16202|        348|       2|      821|  0.99|2022-01-26 16:52:...|\n",
      "|     16216|        357|       2|      945|  0.99|2022-01-24 00:39:...|\n",
      "|     16237|        369|       1|       31|  4.99|2022-01-31 00:12:...|\n",
      "|     16247|        372|       1|      617|  2.99|2022-01-29 12:51:...|\n",
      "|     16249|        373|       2|      257|  4.99|2022-01-29 05:33:...|\n",
      "|     16259|        379|       2|      209|  4.99|2022-01-30 23:02:...|\n",
      "+----------+-----------+--------+---------+------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payment_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+------------+-----------+-------------------+--------+-------------------+\n",
      "|rental_id|        rental_date|inventory_id|customer_id|        return_date|staff_id|        last_update|\n",
      "+---------+-------------------+------------+-----------+-------------------+--------+-------------------+\n",
      "|        2|2022-05-24 21:54:33|        1525|        459|2022-05-28 18:40:33|       1|2022-02-16 02:30:53|\n",
      "|        3|2022-05-24 22:03:39|        1711|        408|2022-06-01 21:12:39|       1|2022-02-16 02:30:53|\n",
      "|        4|2022-05-24 22:04:41|        2452|        333|2022-06-03 00:43:41|       2|2022-02-16 02:30:53|\n",
      "|        5|2022-05-24 22:05:21|        2079|        222|2022-06-02 03:33:21|       1|2022-02-16 02:30:53|\n",
      "|        6|2022-05-24 22:08:07|        2792|        549|2022-05-27 00:32:07|       1|2022-02-16 02:30:53|\n",
      "|        7|2022-05-24 22:11:53|        3995|        269|2022-05-29 19:34:53|       2|2022-02-16 02:30:53|\n",
      "|        8|2022-05-24 22:31:46|        2346|        239|2022-05-27 22:33:46|       2|2022-02-16 02:30:53|\n",
      "|        9|2022-05-24 23:00:40|        2580|        126|2022-05-27 23:22:40|       1|2022-02-16 02:30:53|\n",
      "|       10|2022-05-24 23:02:21|        1824|        399|2022-05-31 21:44:21|       2|2022-02-16 02:30:53|\n",
      "|       11|2022-05-24 23:09:02|        4443|        142|2022-06-02 19:56:02|       2|2022-02-16 02:30:53|\n",
      "+---------+-------------------+------------+-----------+-------------------+--------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rental_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+--------+-------------------+\n",
      "|inventory_id|film_id|store_id|        last_update|\n",
      "+------------+-------+--------+-------------------+\n",
      "|           1|      1|       1|2022-02-15 10:09:17|\n",
      "|           2|      1|       1|2022-02-15 10:09:17|\n",
      "|           3|      1|       1|2022-02-15 10:09:17|\n",
      "|           4|      1|       1|2022-02-15 10:09:17|\n",
      "|           5|      1|       2|2022-02-15 10:09:17|\n",
      "|           6|      1|       2|2022-02-15 10:09:17|\n",
      "|           7|      1|       2|2022-02-15 10:09:17|\n",
      "|           8|      1|       2|2022-02-15 10:09:17|\n",
      "|           9|      2|       2|2022-02-15 10:09:17|\n",
      "|          10|      2|       2|2022-02-15 10:09:17|\n",
      "+------------+-------+--------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inventory_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------------------+\n",
      "|film_id|category_id|        last_update|\n",
      "+-------+-----------+-------------------+\n",
      "|      1|          6|2022-02-15 10:07:09|\n",
      "|      2|         11|2022-02-15 10:07:09|\n",
      "|      3|          6|2022-02-15 10:07:09|\n",
      "|      4|         11|2022-02-15 10:07:09|\n",
      "|      5|          8|2022-02-15 10:07:09|\n",
      "|      6|          9|2022-02-15 10:07:09|\n",
      "|      7|          5|2022-02-15 10:07:09|\n",
      "|      8|         11|2022-02-15 10:07:09|\n",
      "|      9|         11|2022-02-15 10:07:09|\n",
      "|     10|         15|2022-02-15 10:07:09|\n",
      "+-------+-----------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "film_category_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-------------------+\n",
      "|category_id|       name|        last_update|\n",
      "+-----------+-----------+-------------------+\n",
      "|          1|     Action|2022-02-15 09:46:27|\n",
      "|          2|  Animation|2022-02-15 09:46:27|\n",
      "|          3|   Children|2022-02-15 09:46:27|\n",
      "|          4|   Classics|2022-02-15 09:46:27|\n",
      "|          5|     Comedy|2022-02-15 09:46:27|\n",
      "|          6|Documentary|2022-02-15 09:46:27|\n",
      "|          7|      Drama|2022-02-15 09:46:27|\n",
      "|          8|     Family|2022-02-15 09:46:27|\n",
      "|          9|    Foreign|2022-02-15 09:46:27|\n",
      "|         10|      Games|2022-02-15 09:46:27|\n",
      "+-----------+-----------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "max_pay_cat_df: DataFrame = category_df.join(film_category_df , on=\"category_id\" , how=\"inner\"). \\\n",
    "    join(inventory_df  , on=\"film_id\"  ,  how=\"inner\"). \\\n",
    "    join(rental_df   , on=\"inventory_id\"   ,  how=\"inner\"). \\\n",
    "    join(payment_df , on=\"rental_id\"  ,  how=\"inner\"). \\\n",
    "    groupBy(category_df.name).agg(f.sum(payment_df.amount).alias(\"rent_amt\")).orderBy(f.col(\"rent_amt\").desc()).limit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+\n",
      "|  name|         rent_amt|\n",
      "+------+-----------------+\n",
      "|Sports|5314.209999999843|\n",
      "+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_pay_cat_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "4.\n",
    "Вивести назви фільмів, яких не має в inventory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------------+------------+-----------+--------------------+---------------+-----------+------+----------------+------+--------------------+--------------------+--------------------+\n",
      "|film_id|           title|         description|release_year|language_id|original_language_id|rental_duration|rental_rate|length|replacement_cost|rating|         last_update|    special_features|            fulltext|\n",
      "+-------+----------------+--------------------+------------+-----------+--------------------+---------------+-----------+------+----------------+------+--------------------+--------------------+--------------------+\n",
      "|      1|ACADEMY DINOSAUR|A Epic Drama of a...|        2006|          1|                NULL|              6|       0.99|    86|           20.99|    PG|2022-09-10 16:46:...|{Deleted Scenes,B...|'academi':1 'batt...|\n",
      "|      2|  ACE GOLDFINGER|A Astounding Epis...|        2006|          1|                NULL|              3|       4.99|    48|           12.99|     G|2022-09-10 16:46:...|{Trailers,Deleted...|'ace':1 'administ...|\n",
      "|      3|ADAPTATION HOLES|A Astounding Refl...|        2006|          1|                NULL|              7|       2.99|    50|           18.99| NC-17|2022-09-10 16:46:...|{Trailers,Deleted...|'adapt':1 'astoun...|\n",
      "|      4|AFFAIR PREJUDICE|A Fanciful Docume...|        2006|          1|                NULL|              5|       2.99|   117|           26.99|     G|2022-09-10 16:46:...|{Commentaries,Beh...|'affair':1 'chase...|\n",
      "|      5|     AFRICAN EGG|A Fast-Paced Docu...|        2006|          1|                NULL|              6|       2.99|   130|           22.99|     G|2022-09-10 16:46:...|    {Deleted Scenes}|'african':1 'chef...|\n",
      "|      6|    AGENT TRUMAN|A Intrepid Panora...|        2006|          1|                NULL|              3|       2.99|   169|           17.99|    PG|2022-09-10 16:46:...|    {Deleted Scenes}|'agent':1 'ancien...|\n",
      "|      7| AIRPLANE SIERRA|A Touching Saga o...|        2006|          1|                NULL|              6|       4.99|    62|           28.99| PG-13|2022-09-10 16:46:...|{Trailers,Deleted...|'airplan':1 'boat...|\n",
      "|      8| AIRPORT POLLOCK|A Epic Tale of a ...|        2006|          1|                NULL|              6|       4.99|    54|           15.99|     R|2022-09-10 16:46:...|          {Trailers}|'airport':1 'anci...|\n",
      "|      9|   ALABAMA DEVIL|A Thoughtful Pano...|        2006|          1|                NULL|              3|       2.99|   114|           21.99| PG-13|2022-09-10 16:46:...|{Trailers,Deleted...|'administr':9 'al...|\n",
      "|     10|ALADDIN CALENDAR|A Action-Packed T...|        2006|          1|                NULL|              6|       4.99|    63|           24.99| NC-17|2022-09-10 16:46:...|{Trailers,Deleted...|'action':5 'actio...|\n",
      "+-------+----------------+--------------------+------------+-----------+--------------------+---------------+-----------+------+----------------+------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "film_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "film_notin_inventory_df: DataFrame = film_df.join(inventory_df, on=\"film_id\" , how=\"left_anti\").select(\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               title|\n",
      "+--------------------+\n",
      "|      ALICE FANTASIA|\n",
      "|         APOLLO TEEN|\n",
      "|      ARGONAUTS TOWN|\n",
      "|       ARK RIDGEMONT|\n",
      "|ARSENIC INDEPENDENCE|\n",
      "|   BOONDOCK BALLROOM|\n",
      "|       BUTCH PANTHER|\n",
      "|       CATCH AMISTAD|\n",
      "| CHINATOWN GLADIATOR|\n",
      "|      CHOCOLATE DUCK|\n",
      "|COMMANDMENTS EXPRESS|\n",
      "|    CROSSING DIVORCE|\n",
      "|     CROWDS TELEMARK|\n",
      "|    CRYSTAL BREAKING|\n",
      "|          DAZED PUNK|\n",
      "|DELIVERANCE MULHO...|\n",
      "|   FIREHOUSE VIETNAM|\n",
      "|       FLOATS GARDEN|\n",
      "|FRANKENSTEIN STRA...|\n",
      "|  GLADIATOR WESTWARD|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "film_notin_inventory_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "5.\n",
    "Вивести топ 3 актори, які найбільше зʼявлялись в категорії фільмів “Children”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#table with only \"children\" cat\n",
    "children_category_df:  DataFrame =category_df.filter(f.col(\"name\") == \"Children\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-------------------+\n",
      "|category_id|    name|        last_update|\n",
      "+-----------+--------+-------------------+\n",
      "|          3|Children|2022-02-15 09:46:27|\n",
      "+-----------+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "children_category_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+-------------------+\n",
      "|actor_id|first_name|last_name|        last_update|\n",
      "+--------+----------+---------+-------------------+\n",
      "|       1|  PENELOPE|  GUINESS|2022-02-15 09:34:33|\n",
      "|       2|      NICK| WAHLBERG|2022-02-15 09:34:33|\n",
      "|       3|        ED|    CHASE|2022-02-15 09:34:33|\n",
      "+--------+----------+---------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actor_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-------------------+\n",
      "|actor_id|film_id|        last_update|\n",
      "+--------+-------+-------------------+\n",
      "|       1|      1|2022-02-15 10:05:03|\n",
      "|       1|     23|2022-02-15 10:05:03|\n",
      "|       1|     25|2022-02-15 10:05:03|\n",
      "+--------+-------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "film_actor_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------------------+\n",
      "|film_id|category_id|        last_update|\n",
      "+-------+-----------+-------------------+\n",
      "|      1|          6|2022-02-15 10:07:09|\n",
      "|      2|         11|2022-02-15 10:07:09|\n",
      "|      3|          6|2022-02-15 10:07:09|\n",
      "+-------+-----------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "film_category_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_actor_child_df: DataFrame = actor_df.join(film_actor_df , on=\"actor_id\" , how=\"inner\"). \\\n",
    "    join(film_category_df  , on=\"film_id\"  ,  how=\"inner\"). \\\n",
    "    join(children_category_df   , on=\"category_id\"   ,  how=\"inner\"). \\\n",
    "    groupBy(actor_df.first_name, actor_df.last_name).agg(f.count(film_actor_df.film_id).alias(\"cnt_film\")).orderBy(f.col(\"cnt_film\").desc()).limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------+\n",
      "|first_name|last_name|cnt_film|\n",
      "+----------+---------+--------+\n",
      "|     HELEN|   VOIGHT|       7|\n",
      "|     SUSAN|    DAVIS|       6|\n",
      "|     RALPH|     CRUZ|       5|\n",
      "+----------+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top3_actor_child_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Stop Spark session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
